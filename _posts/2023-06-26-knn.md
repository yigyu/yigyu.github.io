---
layout: single
title: "stanford cs231n assignment 1 - Q1 knn"
categories: cs231n
tags: [computer vision]
---

---

**Inline Question 1**

Notice the structured patterns in the distance matrix, where some rows or columns are visibly brighter. (Note that with the default color scheme black indicates low distances while white indicates high distances.)

- What in the data is the cause behind the distinctly bright rows?
- What causes the columns?

### Answer
 검은색이 가까운 거리, 흰색이 큰 거리를 나타낸다고 했다. 각 row는 한 test data point에 대해 train data point와의 거리를 의미하고 거리가 크다는 것은 각 픽셀 값의 차이를 제곱한 후 더하고 루트를 씌운 값이 크다는 것이다. 각 column은 한 train data point에 대해 test data point와의 거리를 의미한다.

---

**Inline Question 2**

We can also use other distance metrics such as L1 distance.
For pixel values $$p_{ij}^{(k)}$$ at location $$(i,j)$$ of some image $I_k$,

the mean $$\mu$$ across all pixels over all images is $$\mu=\frac{1}{nhw}\sum_{k=1}^n\sum_{i=1}^{h}\sum_{j=1}^{w}p_{ij}^{(k)}$$
And the pixel-wise mean $$\mu_{ij}$$ across all images is
$$\mu_{ij}=\frac{1}{n}\sum_{k=1}^np_{ij}^{(k)}.$$
The general standard deviation $$\sigma$$ and pixel-wise standard deviation $$\sigma_{ij}$$ is defined similarly.

Which of the following preprocessing steps will not change the performance of a Nearest Neighbor classifier that uses L1 distance? Select all that apply. To clarify, both training and test examples are preprocessed in the same way.

1. Subtracting the mean $$\mu$$ ($$\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\mu$$.)
2. Subtracting the per pixel mean $$\mu_{ij}$$  ($$\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\mu_{ij}$$.)
3. Subtracting the mean $$\mu$$ and dividing by the standard deviation $$\sigma$$.
4. Subtracting the pixel-wise mean $$\mu_{ij}$$ and dividing by the pixel-wise standard deviation $$\sigma_{ij}$$.
5. Rotating the coordinate axes of the data, which means rotating all the images by the same angle. Empty regions in the image caused by rotation are padded with a same pixel value and no interpolation is performed.

### Your answer


### Your explanation

---

**Inline Question 3**

Which of the following statements about $$k$$-Nearest Neighbor ($$k$$-NN) are true in a classification setting, and for all $k$? Select all that apply.
1. The decision boundary of the k-NN classifier is linear.
2. The training error of a 1-NN will always be lower than or equal to that of 5-NN.
3. The test error of a 1-NN will always be lower than that of a 5-NN.
4. The time needed to classify a test example with the k-NN classifier grows with the size of the training set.
5. None of the above.

### Your answer
1에 대해서는 약간 헷갈리는 부분이 있고 2와 4라고 생각한다.


### Your explanation

2번 1-NN 같은 경우 training error는 없다. 왜냐하면 하나의 data point가 자신의 data point를 보면 어떤 distance metric을 이용하더라도 거리가 0이므로 옳게 예측하게 된다. 따라서 1-NN의 training error는 5-NN의 training error보다 낮거나 같다고 볼 수 있다.

4번 k-NN classifier는 input data에 대해 모든 train data와의 거리를 측정하고 낮은 거리부터 탐색하기 때문에 train set의 크기가 커지면 classifiy에 걸리는 시간이 증가한다.

---
**implementation**

![two_loops](/assets/images/2023-06-26-knn/two_loops.png)

![one_loops](/assets/images/2023-06-26-knn/one_loop.png)

![no_loop](/assets/images/2023-06-26-knn/no_loop.png)
위 3개의 코드는 test set에 대해서 기존에 학습했던 train set의 data들과 distance를 측정하는 코드이다. 

![closet_y](/assets/images/2023-06-26-knn/closet_y.png)

![predict](/assets/images/2023-06-26-knn/predict.png)
argsort() 기능을 이용해 한 test data point에 대해 train data set에 대한 distance를 오름차순으로 정렬하고, 앞에서 부터 k개의 data point를 뽑아온다. 뽑아온 k개의 data point들의 label을 확인하고 가장 많은 label을 가진 data point의 label을 test data point의 label로 예측한다.

![split_fold](/assets/images/2023-06-26-knn/split_fold.png)

![knn_cross_validation](/assets/images/2023-06-26-knn/knn_cross_validation.png)
train data set을 num_folds개의 fold 단위로 분할하고 train set과 validation set으로 나눈다. 그리고 validation set에 대해 k-NN classifier를 학습시키고 validation set에 대한 accuracy를 구한다. 이 과정을 num_folds번 반복하고 각각의 accuracy를 평균내어 최종 accuracy를 구한다.

yigyu's repository : [https://github.com/yigyu/cs231n](https://github.com/yigyu/cs231n)

assignment link : [https://cs231n.github.io/assignments2023/assignment1/](https://cs231n.github.io/assignments2023/assignment1/)
